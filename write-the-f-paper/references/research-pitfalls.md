<research_pitfalls>

<purpose>
This document catalogs literature research mistakes and provides verification strategies for academic writing.
</purpose>

<known_pitfalls>

<pitfall_citation_scope>
**What**: Citing a paper for a claim it doesn't actually make
**Example**: Citing Smith2023 for "effect size of 0.5" when Smith2023 reports a different study
**Why it happens**: Relying on secondary sources or memory instead of checking primary source
**Prevention**:
```xml
<verification_checklist>
**CRITICAL**: For every citation:
□ Have I read the actual source (not just abstract)?
□ Does the source actually say what I'm claiming?
□ Is the page/section reference correct?
□ Am I citing the original source (not a secondary mention)?
</verification_checklist>
```
</pitfall_citation_scope>

<pitfall_outdated_literature>
**What**: Citing outdated findings that have been superseded
**Example**: Citing a 2010 meta-analysis when a 2023 one exists with different conclusions
**Why it happens**: Not checking for recent literature updates
**Prevention**:
```xml
<verification_checklist>
□ Search for systematic reviews/meta-analyses (most current)
□ Check citation counts and "cited by" for newer work
□ Verify no replication failures or corrections exist
□ Ensure methodology hasn't been superseded
</verification_checklist>
```
</pitfall_outdated_literature>

<pitfall_cherry_picking>
**What**: Only citing sources that support your argument, ignoring contradictory evidence
**Example**: Claiming "research consistently shows X" while ignoring studies showing not-X
**Why it happens**: Confirmation bias, incomplete literature search
**Prevention**:
```xml
<verification_checklist>
□ Search for contradictory evidence explicitly
□ Check for debate/controversy in the field
□ Include limitations and alternative interpretations
□ Acknowledge conflicting findings in Discussion
</verification_checklist>
```
</pitfall_cherry_picking>

<pitfall_misattribution>
**What**: Attributing ideas to wrong sources or claiming originality for existing ideas
**Example**: Claiming "we are the first to..." when prior work exists
**Why it happens**: Incomplete literature review
**Prevention**:
```xml
<verification_checklist>
□ Search for prior work using multiple query formulations
□ Check key papers' references for relevant prior work
□ Verify "first" claims with thorough search
□ When in doubt, phrase as "to our knowledge"
</verification_checklist>
```
</pitfall_misattribution>

<pitfall_source_quality>
**What**: Citing low-quality or non-peer-reviewed sources for empirical claims
**Example**: Citing a blog post or preprint for established facts
**Why it happens**: First search result used without quality check
**Prevention**:
```xml
<source_verification>
For empirical claims:
- [ ] Peer-reviewed journal (preferred)
- [ ] Published conference proceedings (acceptable)
- [ ] Government/institutional reports (for statistics)
- [ ] Preprints only if noting "not peer-reviewed"
</source_verification>
```
</pitfall_source_quality>

<pitfall_false_consensus>
**What**: Claiming broad consensus when field is actually divided
**Example**: "It is well established that..." when significant debate exists
**Why it happens**: Exposure to limited subset of literature
**Prevention**:
```xml
<verification_checklist>
□ Check for review papers discussing field debates
□ Search for "critique of X" or "X controversy"
□ Verify claim with multiple independent sources
□ Use hedged language if consensus uncertain
</verification_checklist>
```
</pitfall_false_consensus>

<pitfall_effect_size_conflation>
**What**: Confusing statistical significance with practical importance
**Example**: Citing p < .001 without noting tiny effect size
**Why it happens**: Focus on p-values over effect sizes
**Prevention**:
```xml
<verification_checklist>
□ Report effect sizes, not just significance
□ Check sample size (large samples find tiny effects)
□ Compare to meaningful benchmarks in field
□ Note practical vs. statistical significance
</verification_checklist>
```
</pitfall_effect_size_conflation>

<pitfall_definitional_drift>
**What**: Using terms inconsistently or differently from cited sources
**Example**: Your definition of "resilience" differs from cited paper's definition
**Why it happens**: Not checking how sources define key terms
**Prevention**:
```xml
<verification_checklist>
□ Define key terms explicitly in paper
□ Check cited sources use terms same way
□ Note when sources use different definitions
□ Be consistent throughout your paper
</verification_checklist>
```
</pitfall_definitional_drift>
</known_pitfalls>

<red_flags>

<red_flag_all_support>
**Warning**: All cited sources perfectly support your claims
**Problem**: Real literature has nuance and contradictions
**Action**: Look harder for alternative viewpoints
</red_flag_all_support>

<red_flag_old_citations>
**Warning**: Most citations are >5-10 years old in active field
**Problem**: May be missing recent developments
**Action**: Update literature search with recent date filters
</red_flag_old_citations>

<red_flag_secondary_citations>
**Warning**: "Smith (2020) reports that Jones (2018) found..."
**Problem**: Telephone game introduces errors
**Action**: Go to primary source (Jones 2018) directly
</red_flag_secondary_citations>

<red_flag_no_limitations>
**Warning**: No limitations mentioned for cited studies
**Problem**: All studies have limitations
**Action**: Note relevant limitations, especially for key claims
</red_flag_no_limitations>

<red_flag_unanimous_field>
**Warning**: "All researchers agree..." or "The literature clearly shows..."
**Problem**: Fields rarely have complete consensus
**Action**: Verify with meta-analyses, check for debates
</red_flag_unanimous_field>
</red_flags>

<literature_search_best_practices>

**1. Use multiple databases:**
- Google Scholar (broad)
- Field-specific databases (PubMed, PsycINFO, etc.)
- Citation tracking (forward and backward)

**2. Use multiple query formulations:**
- Synonyms and related terms
- Different orderings
- Include/exclude specific contexts

**3. Check "cited by" for key papers:**
- Finds newer work building on foundations
- Reveals debates and critiques

**4. Read abstracts critically:**
- Distinguish methods, findings, interpretations
- Note sample sizes and contexts

**5. Maintain bibliography as you go:**
- Update sources/literature.md continuously
- Note relevance and key quotes
- Track what you've actually read vs. skimmed
</literature_search_best_practices>

<quick_reference>

Before finalizing citations, verify:

- [ ] Primary source actually read (not just abstract)
- [ ] Claim accurately reflects source's findings
- [ ] No newer work supersedes this finding
- [ ] Contradictory evidence acknowledged
- [ ] Source quality appropriate for claim type
- [ ] Key terms used consistently with sources
- [ ] Effect sizes reported where relevant
- [ ] Consensus claims verified with multiple sources
- [ ] "First to" claims thoroughly searched
- [ ] All references formatted correctly

**Living Document**: Update after each citation error discovered
</quick_reference>
</research_pitfalls>
